{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "\n",
    "<br><h1 style=\"list-style:none\"> A3 - Analysis Report</h1><br>\n",
    "<b>DAT-5303 | Machine Learning</b><br>\n",
    "Fabian Jaskotka<br>\n",
    "Hult International Business School<br><br>\n",
    "\n",
    "<p>Apprentice Chef, Inc.<br>\n",
    "   Key Insights into:\n",
    "</p>\n",
    "    <ul>\n",
    "        <li>Which factors drive Revenue</li>\n",
    "        <li>Which customers are most likely to subscribe to the halfway there service</li>\n",
    "    </ul>\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Management Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Introduction</b><br><br>\n",
    "Following the request of Apprentice Chef to help to better understand how much revenue to expect from their customers as well as predict which customers would sign up for the new <i>Halfway There</i> program, machine learning models have been developed and their derived insights are presented in this report.<br><br>\n",
    "\n",
    "<b>Expecting customer revenue</b><br><br>\n",
    "The most relevant insight for the expectation of revenue of a customer appears to be the Average Preparation Instruction video watching time. A 1% increase in watching times can be associated with a 50% increase in expected revenue. Therefore, instruction videos seem very helpful and shall be advertised more to clients.<br>\n",
    "Also the rating of the meals affects the revenue that can be expected from a customer. A customer with a 4-star median meal rating is expected to generate a revenue that is about 12% higher than that of a customer with a 1-star median meal rating. Hence, customer satisfaction shall be focused on and concrete improvement steps analyzed.<br>\n",
    "(ARD Model, R-Square: 0.792)<br><br>\n",
    "\n",
    "<b>Predicting Campaign Acceptance</b><br><br>\n",
    "The most significant impact on the acceptance of the campaign comes from the email addresses. Especially people that signed up with junk classified email addresses (@me.com, etc.) are particularly likely to accept the offer. Therefore, focus shall be put on the advertisement to people with these email addresses.<br>\n",
    "Additionally, the number of cancellations before noon plays an important role in predicting the customerâ€™s acceptance of the <i>Halfway There</i> campaign. Customers with less than 2 cancellations are more likely to accept. Marketing the campaign to these customers can be considered especially promising.<br>\n",
    "(Classification Tree, AUC-score: 0.73)<br><br>\n",
    "\n",
    "<b>Conclusion</b><br><br>\n",
    "The four insights presented above paired with their brief recommendations shall enable Apprentice Chef to take control over customer generated revenue and allow for an efficient planing for a successful <i>Halfway There</i> campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#importing necessary packages\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gender_guesser.detector as gender\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#for linear regression\n",
    "import sklearn.linear_model \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#for classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import export_graphviz             # exports graphics\n",
    "from six import StringIO                             # saves objects in memory\n",
    "from IPython.display import Image                    # displays on frontend\n",
    "import pydotplus                                     # interprets dot objects\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting seed\n",
    "rand.seed(a=327)\n",
    "\n",
    "#defining filepath for dataset\n",
    "file = \"./datasets/Apprentice_Chef_Dataset.xlsx\"\n",
    "\n",
    "#matching datatypes\n",
    "data_types = {\"AVG_CLICKS_PER_VISIT\" : float}\n",
    "\n",
    "#importing dataset\n",
    "chef = pd.read_excel(io = file,\n",
    "                    dtype = data_types)\n",
    "\n",
    "#changing column name of Largest_Order_Size\n",
    "chef.columns = ['REVENUE', 'CROSS_SELL_SUCCESS', 'NAME', 'EMAIL', 'FIRST_NAME',\n",
    "       'FAMILY_NAME', 'TOTAL_MEALS_ORDERED', 'UNIQUE_MEALS_PURCH',\n",
    "       'CONTACTS_W_CUSTOMER_SERVICE', 'PRODUCT_CATEGORIES_VIEWED',\n",
    "       'AVG_TIME_PER_SITE_VISIT', 'MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON',\n",
    "       'CANCELLATIONS_AFTER_NOON', 'TASTES_AND_PREFERENCES', 'PC_LOGINS',\n",
    "       'MOBILE_LOGINS', 'WEEKLY_PLAN', 'EARLY_DELIVERIES', 'LATE_DELIVERIES',\n",
    "       'PACKAGE_LOCKER', 'REFRIGERATED_LOCKER', 'AVG_PREP_VID_TIME',\n",
    "       'AVG_NUMBER_MEALS', 'MASTER_CLASSES_ATTENDED', 'MEDIAN_MEAL_RATING',\n",
    "       'AVG_CLICKS_PER_VISIT', 'TOTAL_PHOTOS_VIEWED']\n",
    "\n",
    "\n",
    "# formatting and printing the dimensions of the dataset\n",
    "print(f\"\"\"\n",
    "Size of Original Dataset\n",
    "------------------------\n",
    "Observations: {chef.shape[0]}\n",
    "Features:     {chef.shape[1]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "chef.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping Family name variable\n",
    "chef = chef.drop('FAMILY_NAME', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# optimal_neighbors\n",
    "######################################## \n",
    "def optimal_neighbors(X_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "X_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the X data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing X_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(X_data)\n",
    "        X_scaled           = scaler.transform(X_data)\n",
    "        X_scaled_df        = pd.DataFrame(X_scaled)\n",
    "        X_data             = X_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(X_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revenue Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logarithmic transformation of Revenue\n",
    "chef['LOG_REVENUE'] = np.log10(chef['REVENUE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photos viewed at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy variables\n",
    "chef['PHOTOS_VIEWED_AT_ALL'] = 0\n",
    "\n",
    "\n",
    "#creating loop to iterate over dataset\n",
    "for index, value in chef.iterrows():\n",
    "        \n",
    "    #assigning 1 to customers that already viewed photos\n",
    "    if chef.loc[index, 'TOTAL_PHOTOS_VIEWED'] > 0:\n",
    "        chef.loc[index, 'PHOTOS_VIEWED_AT_ALL'] = 1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancellations after noon per Meal ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cancellation after noon per meal ordered\n",
    "chef['CANCELLATION_AFTER_NOON_PMO'] = chef['CANCELLATIONS_AFTER_NOON'] / chef['TOTAL_MEALS_ORDERED']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contacts with customer service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Meal Ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating feature as ratio of service requests per meal ordered\n",
    "chef['CONTACTS_W_CUSTOMER_SERVICE_PMO'] =  chef['TOTAL_MEALS_ORDERED'] / chef['CONTACTS_W_CUSTOMER_SERVICE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming variable\n",
    "chef['LOG_CONTACTS_W_CUSTOMER_SERVICE_PMO'] = np.log10(chef['CONTACTS_W_CUSTOMER_SERVICE_PMO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split at 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholder list\n",
    "placeholder_lst = []\n",
    "#dummy variables for CONTACTS_W_CUSTOMER_SERVICE_PMO\n",
    "for item in chef['LOG_CONTACTS_W_CUSTOMER_SERVICE_PMO']:\n",
    "    if item > 0.25:\n",
    "        placeholder_lst.append(1)\n",
    "        \n",
    "    else:\n",
    "        placeholder_lst.append(0)\n",
    "\n",
    "#adding new feature to dataset\n",
    "chef['CS_PMO_MIN_2'] = pd.Series(placeholder_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split at 10 Contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "#for loop to loop over Contacts_W_Customer service\n",
    "for item in chef['CONTACTS_W_CUSTOMER_SERVICE']:\n",
    "    \n",
    "    if item <= 10:\n",
    "        placeholder_lst.append(0)\n",
    "        \n",
    "    else:\n",
    "        placeholder_lst.append(1)\n",
    "        \n",
    "chef['CONTACTS_W_CUSTOMER_SERVICE_ABOVETEN'] = pd.Series(placeholder_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Meals Ordered Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating feature for above 20 meals ordered\n",
    "placeholder_lst = []\n",
    "\n",
    "for item in chef['TOTAL_MEALS_ORDERED']:\n",
    "    if item > 20:\n",
    "        placeholder_lst.append(1)\n",
    "    else:\n",
    "        placeholder_lst.append(0)\n",
    "\n",
    "#adding new feature to dataset\n",
    "chef['TOTAL_MEALS_ABOVE20'] = pd.Series(placeholder_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Meals per Meals Ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating feature\n",
    "chef['UNIQUE_MEALS_PURCH_PMO'] = chef['UNIQUE_MEALS_PURCH'] / chef['TOTAL_MEALS_ORDERED']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masterclasses attended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variable\n",
    "master_dummy = pd.get_dummies(chef['MASTER_CLASSES_ATTENDED'])\n",
    "\n",
    "#renaming the columns of the dummy dataset\n",
    "master_dummy.columns = ['NO_MASTER_CLASSES_ATTENDED', 'ONE_MASTER_CLASSES_ATTENDED', \n",
    "                        'TWO_MASTER_CLASSES_ATTENDED', 'THREE_MASTER_CLASSES_ATTENDED']\n",
    "\n",
    "#adding dummy variables as new features\n",
    "chef = chef.join([master_dummy.iloc[:, 1:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median Meal Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variable\n",
    "rating_dummy = pd.get_dummies(chef['MEDIAN_MEAL_RATING'])\n",
    "\n",
    "#renaming columns of dummy dataset\n",
    "rating_dummy.columns = ['ONE_MEDIAN_MEAL_RATING', 'TWO_MEDIAN_MEAL_RATING', \n",
    "                       'THREE_MEDIAN_MEAL_RATING', 'FOUR_MEDIAN_MEAL_RATING',\n",
    "                       'FIVE_MEDIAN_MEAL_RATING']\n",
    "\n",
    "#adding new dummy variables to chef dataset\n",
    "chef = chef.join([rating_dummy.iloc[:, 1:4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Clicks per Site Visit Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "#looping over Average click per visit feature\n",
    "for item in chef['AVG_CLICKS_PER_VISIT']:\n",
    "    if item > 10:\n",
    "        placeholder_lst.append(1)\n",
    "        \n",
    "    else:\n",
    "        placeholder_lst.append(0)\n",
    "\n",
    "#transforming list to Series and adding to dataset\n",
    "chef['AVG_CLICKS_PER_VISIT_ABOVETEN'] = pd.Series(placeholder_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# text_split_feature\n",
    "#########################\n",
    "def text_split_feature(col, df, sep=' ', new_col_name='number_of_names'):\n",
    "    \"\"\"\n",
    "Splits values in a string Series (as part of a DataFrame) and sums the number\n",
    "of resulting items. Automatically appends summed column to original DataFrame.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "col          : column to split\n",
    "df           : DataFrame where column is located\n",
    "sep          : string sequence to split by, default ' '\n",
    "new_col_name : name of new column after summing split, default\n",
    "               'number_of_names'\n",
    "\"\"\"\n",
    "    \n",
    "    df[new_col_name] = 0\n",
    "    \n",
    "    \n",
    "    for index, val in df.iterrows():\n",
    "        df.loc[index, new_col_name] = len(df.loc[index, col].split(sep = ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling text_split_function to count number of names\n",
    "text_split_feature(col = 'NAME', \n",
    "                   df = chef,\n",
    "                  new_col_name = 'NUMBER_OF_NAMES')\n",
    "\n",
    "#dropping the name feature\n",
    "chef = chef.drop('NAME', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in the gender List\n",
    "gender_file = \"./datasets/chef_gender.xlsx\"\n",
    "\n",
    "gender = pd.read_excel(io = gender_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variables\n",
    "one_hot_gender = pd.get_dummies(gender)\n",
    "\n",
    "one_hot_gender.columns = ['andy', 'FEMALE', 'MALE', 'mostly_female', \n",
    "                          'mostly_male','unknown']\n",
    "\n",
    "#dropping variables related to gender\n",
    "chef = chef.drop(['FIRST_NAME'], axis = 1)\n",
    "\n",
    "#joining dummy variables to chef\n",
    "chef = chef.join(one_hot_gender.iloc[:, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating empty list\n",
    "placeholder_lst = []\n",
    "\n",
    "for index, value in chef.iterrows():\n",
    "    \n",
    "    split_email = chef.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "email_df.columns = ['0', 'EMAIL_DOMAIN']\n",
    "\n",
    "#adding email domain feature to chef dataset\n",
    "chef = pd.concat([chef, email_df['EMAIL_DOMAIN']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping mail domains in professional, personal and junk\n",
    "professional_mail = ['@mmm.com', '@amex.com', '@apple.com', '@boeing.com', '@caterpillar.com', \n",
    "                    '@chevron.com', '@cisco.com', '@cocacola.com', '@disney.com', '@dupont.com', \n",
    "                    '@exxon.com', '@ge.org', '@goldmansacs.com', '@homedepot.com', '@ibm.com', \n",
    "                    '@intel.com', '@jnj.com', '@jpmorgan.com', '@mcdonalds.com', '@merck.com', \n",
    "                     '@microsoft.com', '@nike.com', '@pfizer.com', '@pg.com', '@travelers.com',\n",
    "                    '@unitedtech.com', '@unitedhealth.com', '@verizon.com', '@visa.com', '@walmart.com']\n",
    "\n",
    "personal_mail = ['@gmail.com', '@yahoo.com', '@protonmail.com']\n",
    "\n",
    "junk_mail = ['@me.com', '@aol.com', '@hotmail.com', '@live.com', '@msn.com', '@passport.com']\n",
    "\n",
    "\n",
    "#placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "\n",
    "#loop to go over domains and assign categories\n",
    "for domain in chef['EMAIL_DOMAIN']:\n",
    "    \n",
    "    if '@' + domain in professional_mail:\n",
    "        placeholder_lst.append('PROFESSIONAL_MAIL')\n",
    "        \n",
    "    elif '@' + domain in personal_mail:\n",
    "        placeholder_lst.append('PERSONAL_MAIL')\n",
    "        \n",
    "    elif '@' + domain in junk_mail:\n",
    "        placeholder_lst.append('JUNK_MAIL')\n",
    "\n",
    "#creating new feature, gomain group\n",
    "chef['DOMAIN_GROUP'] = pd.Series(placeholder_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding of domain group variable\n",
    "one_hot_domain = pd.get_dummies(chef['DOMAIN_GROUP'])\n",
    "\n",
    "#dropping categorical variables after encoding\n",
    "chef = chef.drop('DOMAIN_GROUP', axis = 1 )\n",
    "\n",
    "#adding dummy variables to dataset\n",
    "chef = chef.join([one_hot_domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the variables of types object\n",
    "chef = chef.drop(['EMAIL', 'EMAIL_DOMAIN'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with all features to be transformed\n",
    "log_features = ['TOTAL_MEALS_ORDERED', 'CONTACTS_W_CUSTOMER_SERVICE', \n",
    "                'AVG_PREP_VID_TIME', 'AVG_NUMBER_MEALS',\n",
    "               'CONTACTS_W_CUSTOMER_SERVICE_PMO','UNIQUE_MEALS_PURCH_PMO']\n",
    "\n",
    "#loop for transformation of all features from dictionary\n",
    "for feature in log_features:\n",
    "    \n",
    "    #logrithmic transformation of features\n",
    "    chef['LOG_'+feature] = np.log10(chef[feature])\n",
    "    \n",
    "\n",
    "#dropping normal form of transformed variables\n",
    "chef = chef.drop(log_features, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionaryfor explainingvariables\n",
    "\n",
    "candidate_dict = {\n",
    "    'regression':['CROSS_SELL_SUCCESS','UNIQUE_MEALS_PURCH',\n",
    "                  'REFRIGERATED_LOCKER','MEDIAN_MEAL_RATING',\n",
    "                  'PHOTOS_VIEWED_AT_ALL','CANCELLATION_AFTER_NOON_PMO',\n",
    "                  'LOG_CONTACTS_W_CUSTOMER_SERVICE',\n",
    "                  'CONTACTS_W_CUSTOMER_SERVICE_ABOVETEN',\n",
    "                  'LOG_CONTACTS_W_CUSTOMER_SERVICE_PMO','CS_PMO_MIN_2',\n",
    "                  'TOTAL_MEALS_ABOVE20','LOG_TOTAL_MEALS_ORDERED',\n",
    "                  'LOG_UNIQUE_MEALS_PURCH_PMO','LOG_AVG_PREP_VID_TIME',\n",
    "                  'LOG_AVG_NUMBER_MEALS','ONE_MASTER_CLASSES_ATTENDED',\n",
    "                  'TWO_MASTER_CLASSES_ATTENDED','THREE_MEDIAN_MEAL_RATING',\n",
    "                  'FOUR_MEDIAN_MEAL_RATING','AVG_CLICKS_PER_VISIT_ABOVETEN'],\n",
    "    \n",
    "    'classification': ['MOBILE_NUMBER','CANCELLATIONS_BEFORE_NOON',\n",
    "                   'TASTES_AND_PREFERENCES','PC_LOGINS','EARLY_DELIVERIES',\n",
    "                   'REFRIGERATED_LOCKER','JUNK_MAIL','PROFESSIONAL_MAIL',\n",
    "                   'MALE', 'NUMBER_OF_NAMES', 'LOG_AVG_PREP_VID_TIME']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating datasets into explanatory and target for regression\n",
    "chef_reg = chef.loc[ : , candidate_dict['regression']]\n",
    "chef_target = chef['REVENUE']\n",
    "chef_target_log = chef['LOG_REVENUE']\n",
    "\n",
    "#seperating datasets into explanatory and target for classification\n",
    "chef_clas = chef.loc[ : , candidate_dict['classification']]\n",
    "chef_goal = chef.loc[ :, 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "#splitting into x_train, x_test, y_train, y_test with all variables\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    chef_reg, \n",
    "    chef_target_log,\n",
    "    test_size = 0.25,\n",
    "    random_state = 219)\n",
    "\n",
    "\n",
    "#splitting into x_train, x_test, y_train, y_test with all variables\n",
    "x_train_clas, x_test_clas, y_train_clas, y_test_clas = train_test_split(\n",
    "    chef_clas, \n",
    "    chef_goal,\n",
    "    test_size = 0.25,\n",
    "    random_state = 219,\n",
    "    stratify = chef_goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARD Model for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a model object\n",
    "ard_model = sklearn.linear_model.ARDRegression(normalize = False)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "ard_fit = ard_model.fit(x_train_reg, y_train_reg)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "ard_pred = ard_fit.predict(x_test_reg)\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "model_type_3 = \"ARD Regression\"\n",
    "ard_train_score = ard_model.score(x_train_reg, y_train_reg).round(4)\n",
    "ard_test_score  = ard_model.score(x_test_reg, y_test_reg).round(4)\n",
    "ard_test_gap = abs(ard_train_score - ard_test_score).round(4)\n",
    "\n",
    "\n",
    "# zipping each feature name to its coefficient\n",
    "ard_model_values = zip(chef_reg.columns, ard_fit.coef_.round(decimals = 5))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "ard_model_lst = [('intercept', ard_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in ard_model_values:\n",
    "    ard_model_lst.append(val)\n",
    "    \n",
    "\n",
    "#setting variable\n",
    "x = 6\n",
    "\n",
    "#loop to delete coefficients\n",
    "while x > 0:\n",
    "    \n",
    "    for feature, coefficient in ard_model_lst:\n",
    "        \n",
    "        if coefficient == 0:\n",
    "            ard_model_lst.remove((feature, coefficient))\n",
    "    \n",
    "    x -= 1\n",
    "  \n",
    "    \n",
    "#calculating model size    \n",
    "model_size_ard = len(ard_model_lst)\n",
    "\n",
    " #printing model output\n",
    "print(f\"\"\"\n",
    "These are the results of the {model_type_3} model\n",
    "---------------------------------------------------\n",
    "Training Score : {ard_train_score}\n",
    "Testing Score  : {ard_test_score}\n",
    "Train-Test Gap : {ard_test_gap}\n",
    "Model Size     : {model_size_ard}\n",
    "\n",
    "\"\"\")   \n",
    "    \n",
    "\n",
    "\n",
    "# checking the results\n",
    "for pair in ard_model_lst:\n",
    "    print(pair)\n",
    "    \n",
    "ard_model_lst = pd.DataFrame(ard_model_lst)\n",
    "\n",
    "ard_model_lst.columns = ['Feature', 'Coefficient']\n",
    "print(ard_model_lst.sort_values('Coefficient', ascending = False))\n",
    "    \n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance_ard = {\n",
    "    \n",
    "    'Model Type'    : [model_type_3],\n",
    "    \n",
    "    \n",
    "    'Training' : [ard_train_score],\n",
    "                  \n",
    "           \n",
    "    'Testing'  : [ard_test_score],\n",
    "    \n",
    "    \n",
    "    'Train-Test Gap' : [ard_test_gap],\n",
    "                   \n",
    "    \n",
    "    'Model Size' : [model_size_ard],\n",
    "                    \n",
    "    'Model'      : [ard_model_lst],\n",
    "    \n",
    "    'Final'      : [\"Yes\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Tree for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# display_tree\n",
    "########################################\n",
    "def display_tree(tree, feature_df, height = 500, width = 800):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    tree       : fitted tree model object\n",
    "        fitted CART model to visualized\n",
    "    feature_df : DataFrame\n",
    "        DataFrame of explanatory features (used to generate labels)\n",
    "    height     : int, default 500\n",
    "        height in pixels to which to constrain image in html\n",
    "    width      : int, default 800\n",
    "        width in pixels to which to constrain image in html\n",
    "    \"\"\"\n",
    "\n",
    "    # visualizing the tree\n",
    "    dot_data = StringIO()\n",
    "\n",
    "    \n",
    "    # exporting tree to graphviz\n",
    "    export_graphviz(decision_tree      = tree,\n",
    "                    out_file           = dot_data,\n",
    "                    filled             = True,\n",
    "                    rounded            = True,\n",
    "                    special_characters = True,\n",
    "                    feature_names      = feature_df.columns)\n",
    "\n",
    "\n",
    "    # declaring a graph object\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "\n",
    "    # creating image\n",
    "    img = Image(graph.create_png(),\n",
    "                height = height,\n",
    "                width  = width)\n",
    "    \n",
    "    return img\n",
    "\n",
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train_clas.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = DecisionTreeClassifier(max_depth=3, min_samples_leaf=21, min_samples_split=4,\n",
    "                       random_state=219)\n",
    "\n",
    "# FIT step is not needed\n",
    "tree_tuned_fit = tree_tuned.fit(x_train_clas, y_train_clas)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned_fit.predict(x_test_clas)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(x_train_clas, y_train_clas).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(x_test_clas, y_test_clas).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_clas,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train_clas, y_train_clas).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(x_test_clas, y_test_clas).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test_clas,\n",
    "                                     y_score = tree_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test_clas, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling display_tree\n",
    "display_tree(tree       = tree_tuned_fit,\n",
    "             feature_df = x_train_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importance\n",
    "plot_feature_importances(tree_tuned_fit,\n",
    "                         train  = x_train_clas,\n",
    "                         export = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
